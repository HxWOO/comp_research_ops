# AI 기반 기업 분석 보고서 자동화 프로젝트 개발 요약

## 1. 프로젝트 목표

OpenAI API를 활용하여 특정 기업의 정보를 분석하고, 그 결과를 바탕으로 사용자 목적에 맞는 Word 보고서를 자동으로 생성하는 파이썬 스크립트를 개발하고, 이 과정을 GitHub Actions로 완전 자동화합니다.

## 2. 개발 과정 및 기능 개선 로그

### Phase 1: 초기 아이디어 및 기본 기능 구현

-   **요구사항**: 특정 기업에 대한 기본 정보를 리서치하고 Word 보고서로 자동 생성.
-   **구현**:
    -   `company_research_project` 디렉토리 생성.
    -   `openai`와 `python-docx` 라이브러리를 사용하여 `company_researcher.py` 스크립트 작성.
    -   OpenAI API 버전 호환성 문제 해결 (`openai>=1.0.0` 대응).
    -   `.env` 파일을 통해 API 키를 안정적으로 로드하도록 개선.

### Phase 2: 보고서 목적 변경 (취업 준비 맞춤)

-   **요구사항**: IT 신입 지원자에게 실질적인 도움이 되도록 보고서 내용 변경.
-   **구현**:
    -   리서치 주제를 '최근 주력 사업', '신입 채용 공고 분석', '입사 지원 전략' 등으로 변경.
    -   AI의 역할을 '기업 분석가'에서 'IT 취업 컨설턴트'로 변경하여 답변의 관점을 수정.
    -   `gpt-4o` 모델을 사용하여 분석의 깊이를 더함.

### Phase 3: 심층 분석 기능 추가 (Legacy & State)

-   **요구사항**: 지원서 작성에 깊이를 더하기 위해, 기업의 과거(Legacy)와 현재(State)를 비교 분석하는 기능 추가.
-   **구현**:
    -   리서치 주제를 '기술적 Legacy 분석', '현재 기술 스택 분석', 'Legacy와 현재의 연결점' 등으로 재구성.
    -   AI의 역할을 '기술 전략 분석가'로 변경하여 심층적인 기술 분석을 유도.
    -   '최근 집중하는 신규 IT 사업' 항목을 추가하여 미래 성장 동력 분석 기능 추가.

### Phase 4: 보고서 가독성 개선

-   **요구사항**: 보고서 내용의 가독성을 높이기 위해, AI가 강조하는 키워드를 **굵은 글씨**로 처리.
-   **구현**:
    -   AI에게 답변 시 중요한 부분은 `**`로 감싸도록 프롬프트 수정.
    -   `generate_report` 함수에 `**`를 파싱하여 해당 텍스트만 굵게 처리하는 로직 추가.

### Phase 5: 완전 자동화 파이프라인 구축

-   **요구사항**: 매일 특정 기업의 보고서를 자동으로 생성하여 GitHub 레포지토리에 커밋.
-   **구현**:
    -   **스크립트 리팩토링**:
        -   `scraper.py`: 코스피 시총 100위 기업 목록을 스크레이핑.
        -   `main.py`: 진행 상태(`progress.txt`)를 관리하며 순서대로 기업을 분석하고 보고서 생성.
    -   **GitHub Actions 워크플로우 (`.github/workflows/daily-report.yml`)**:
        -   매일 정해진 시간에 자동 실행 (Cron Job).
        -   `scraper.py`와 `main.py`를 순차적으로 실행.
        -   생성된 보고서와 진행 상태 파일을 자동으로 커밋 및 푸시.

## 3. 최종 프로젝트 구조

```
company_research_project/
├── .github/
│   └── workflows/
│       └── daily-report.yml  # 자동화 워크플로우
├── output/                   # 생성된 보고서 저장 폴더
├── .env                      # API 키 저장 (Git 무시)
├── .gitignore                # Git 무시 파일 목록
├── main.py                   # 메인 실행 파일 (보고서 생성)
├── scraper.py                # 코스피 100 기업 목록 스크레이퍼
├── requirements.txt          # 파이썬 라이브러리 의존성
└── progress.txt              # 분석 진행 순서 저장
```

## 4. 결론

단순한 정보 조회 스크립트에서 시작하여, 사용자의 구체적인 요구사항을 반영하며 점차 고도화되었습니다. 최종적으로는 매일 코스피 상위 기업을 순차적으로 심층 분석하고, 가독성 높은 보고서를 생성하여 GitHub에 자동으로 아카이빙하는 완전 자동화 파이프라인을 구축했습니다.
